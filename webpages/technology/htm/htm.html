<!DOCTYPE html>
<html>
<head>
	<title>Neuroowl - HTM </title>
	<link rel="stylesheet" type="text/css" href="/style.css" />
	<link rel="shortcut icon" type="image/x-icon" href="/resources/favicon.png" />
	<script type="text/javascript" src="/javascript/jquery-3.1.0.min.js"></script>
	<script type="text/javascript" src="/javascript/navbar-load.js"></script>
</head>
<body>
<div class="navbar"></div>
<div class="text">
	<h1>Hierarchical Temporal Memory</h1>

	<p>Hierarchical Temporal Memory (HTM) is a theoretical framework of the neocortex for both biological and machine intelligence under development by <a href="http://numenta.com/">Numenta</a>.</p>
	
	<h2>Introduction</h2>
	
	<p>
	"The goal of building intelligent machines is not to replicate human behavior, nor to build a brain, nor to create machines to do what humans do.  The goal of building intelligent machines is to create machines that work on
	the same principles as the brain -- machines that are able to learn, discover, and adapt in ways that computers can't and brains can.  HTM is a	theory of the neocortex and a few related brain structures; it is not an 
	attempt to model or understand every part of the human brain." <sup><a href="#1">[1]</a></sup>
	</p>
		
	<h2>HTM Principles</h2>

	<input class="toggle-box" id="p0" type="checkbox">
	<label for="p0"><h3>Common Algorithms in Regions</h3></label>
	<div>
		Every region of the neocortex performs the same set of memory and algorithmic functions, regardless of processing vision, hearing, touch, language, etc.
	</div>

	<input class="toggle-box" id="p1" type="checkbox">
	<label for="p1"><h3>Hierarchy of Regions</h3></label>
	<div>
		Neocortex organizes regions in a hierarchy.
	</div>

	<input class="toggle-box" id="p2" type="checkbox">
	<label for="p2"><h3>Sparse Distributed Representations (SDRs)</h3></label>
	<div>
		Only a small percentage of a population of neurons are active at one time.  Symantic similarity.
	</div>

	<input class="toggle-box" id="p3" type="checkbox">
	<label for="p3"><h3>Sensory Encoders</h3></label>
	<div>
		Converts some type of data into an SDR to be processed by HTM algorithms.
	</div>

	<input class="toggle-box" id="p4" type="checkbox">
	<label for="p4"><h3>Sensory-Motor Systems</h3></label>
	<div>
		We can't build systems that see and hear like humans do without incorporating movement of the eyes, body, and limbs.
	</div>

	<input class="toggle-box" id="p5" type="checkbox">
	<label for="p5"><h3>Streaming Data and Sequence Memory</h3></label>
	<div>

	</div>

	<input class="toggle-box" id="p6" type="checkbox">
	<label for="p6"><h3>On-line Unsupervised Learning</h3></label>
	<div>

	</div>

	<h2>Architecture</h2>

	<input class="toggle-box" id="ar0" type="checkbox">
	<label for="ar0"><h3>Regions</h3></label>
	<div>

		Layers

		<h4>Terms</h4>

		feedforward - inputs coming from lower regions
		feedback - inputs coming from higher regions
		lateral - inputs coming from regions of the same level
	</div>

	<input class="toggle-box" id="ar1" type="checkbox">
	<label for="ar1"><h3>Columns</h3></label>
	<div>
		<h4>Terms</h4>
		
		Overlap
		Proximal
	</div>

	<input class="toggle-box" id="ar2" type="checkbox">
	<label for="ar2"><h3>Cells</h3></label>
	<div>

		<h4>Terms</h4>

		active - an active cell represents a recognized pattern in the context of active cells at the previous time step.  This simulates a neuron outputting action potentials.
		predict - a predict cell represents a potential occourance of a pattern at the next timestep in the context of active cells at the current timestep.  A predict cell has an easier time becoming active than an unpredicted cell.  This simulates a depolarized neuron.
		winner - 
	</div>

	<input class="toggle-box" id="ar3" type="checkbox">
	<label for="ar3"><h3>Dendrite Segments</h3></label>
	<div>
		<p>
		Each dendrite segment has synapses.  For a neuron to recognize a pattern of activity it requires a set of co-located synapses (typically 15-20) that connect to a subset of the cells that are active in the pattern to be
		recognized. Learning to recognize a new pattern is accomplished by the formation of a set of new synapses collocated on a dendritic segment. <a href="#2">[2]</a>
		</p>

		<p>A HTM cell has three types of dendrite segments:</p>

		<h4>Terms</h4>
				
		Basal
		Distal
		Apical
	</div>

	<input class="toggle-box" id="ar4" type="checkbox">
	<label for="ar4"><h3>Synapses</h3></label>
	<div>
		<p>
		Synapses form the fundamental memory storage of the neocortex.  HTM synapses use Hebbian-like learning rules to aquire knowledge about the world.  Over time synapses "grow" towards cells that are often active and 
		"shrink" away from cells that are often inactive.  This is modeled by a scalar value called permanence, floating-point values from 0.0 to 1.0 with a threshold of 0.3.  Note, the graphics display integer values from 0 to
		99 with a threshold of 30 purely for aesthetic purposes.  The synaptic learning rules are the same regardless of the data type.
		</p>

		<p>In HTM, Synapses may be randomly initialized or arranged within a receptive field.  Synapse permanences are initialized on or slightly below the threshold.</p>

		<img src="/webpages/technology/htm/syn-initialization.png" alt="syn-initialization" style="margin: 25px auto">

		<p>Synapses behave in 5 ways:</p>
		<ul>
			<li><b>Grow</b> - If the post-synaptic cell is active, then increment the synapse permanence by the learning rate.</li>
			<li><b>Shrink</b> - If the post-synaptic cell is inactive, then decrement the synapse permanence by the learning rate.</li>
			<li><b>Adapt</b> - If permanence is 0, then move synapse to an unused post-synaptic cell and set the permanence just below the threshold.</li>
			<li><b>Insert</b> - If there are more active post-synaptic cells than synapses, then insert a synapse to an active post-synaptic cell.</li>
			<li><b>Remove</b> - If the synapse permanence is 0 and there are no available active post-synaptic cells, then remove the synapse.</li>
		</ul>

		<img src="/webpages/technology/htm/synapse.png" alt="synapse" style="margin: 25px auto">

		<p>
		"Using a scalar permanence value enables on-line learning in the presence of noise. A previously unseen input pattern could be noise or it could be the start of a new trend that will repeat in the future.  By growing 
		new synapses, the network can start to learn a new pattern when it is first encountered, but only act differently after several presentations of the new pattern. Increasing permanence beyond the threshold means that 
		patterns experienced more than others will take longer to forget." <sup><a href="#2">[2]</a></sup> 
			
		^^^^^^^SEARCH FOR CORRECT REF
		</p>

		<h4>Terms</h4>
		<ul>
			<li><b>pre-synaptic</b> - refering to where a synapse grows from, specifically the neuron dendrites in biology.</li>
			<li><b>post-synaptic</b> - refering to where a synapse grows towards, specifically the neuron axons in biology.</li>
			<li><b>permanence</b> - how connected a synapse is.</li>
			<li><b>threshold</b> - represents the establishment of a synapse.</li>
			<li><b>connected</b> - a synapse that has its permanence equal to or greater than the threshold value and therefore is affected by post-synaptic cell active or inactive states.</li>
			<li><b>unconnected</b> - a synapse that has its permanence less than the threshold value and therefore is not affected by post-synaptic cell active or inactive states.</li>
		</ul>
	</div>

	<h2>Algorithms</h2>

	<input class="toggle-box" id="al0" type="checkbox">
	<label for="al0"><h3>Spatial Pooling</h3></label>
	<div>
		<p>The Spatial Pooling algorithm selects a set of columns that best represent the input SDR at a single time step.  This is how an HTM region processes patterns, concurrent cell activations.</p>

		<img src="/webpages/technology/htm/sp.gif" alt="sp" style="margin: 25px auto">

		<h4>Overlap</h4>

		<p>
		Spatial Pooling must first compute an overlap value for each column.  It does this by comparing each column's proximal dendrite segment synapses with the input SDR.  For each synapse in the column's proximal dendrite 
		segment, if the synapse is connected and the post-synaptic cell is active, increment the column's overlap.  Otherwise there is no effect on the column's overlap.
		</p>

		<h4>Inhibition</h4>

		<p>
		After each column computes its own overlap value, Spatial Pooling activates a specified number of columns with the highest overlap score.  Other columns may represent the input pattern quite well, however they are 
		being inhibited by columns with a stronger match.
		</p>

		<h4>Learning</h4>

		<p>Finally, Spatial Pooling uses the synaptic learning rules found in the previous section.</p>

	</div>

	<input class="toggle-box" id="al1" type="checkbox">
	<label for="al1"><h3>Temporal Memory</h3></label>
	<div>
		<p>The Temporal Memory algorithm uses previous cell states to set current cell states.  This is how an HTM region processes sequences, temporal cell activations.</p>

		<img src="/webpages/technology/htm/tm.gif" alt="tm" style="margin: 25px auto">

		<h4>Activation</h4>

		<p>If a cell in an active column at the current timestep is in the predict state at the previous timestep, then set the cell to the active state.</p>

		<h4>Bursting</h4>

		<p>If no cells in an active column at the current timestep are in the predict state at the previous timestep, then set all cells in the active column to the active state.</p>

		<h4>Prediction</h4>

		<h4>Learning</h4>
	</div>

	<h2>References</h2>

	<ol>
		<li><a name="1" href="http://numenta.com/biological-and-machine-intelligence/">Jeff Hawkins et al. Biological and Machine Intelligence, 2016.</a></li>
		<li><a name="2" href="http://journal.frontiersin.org/article/10.3389/fncir.2016.00023/full">Subutai Ahmad and Yuwei Chu. Annotated Bibliography for HTM Researchers, 2016.</a></li>
		<li><a name="3" href="https://github.com/numenta/nupic.research/blob/master/docs/bibliography/htm_bibliography.pdf">Subutai Ahmad and Yuwei Chu. Annotated Bibliography for HTM Researchers, 2016.</a></li>
		<li><a name="4" href="https://arxiv.org/abs/1512.05463">Yuwei Cui, Subutai Ahmad and Jeff Hawkins. Continuous Online Sequence Learning with an Unsupervised Neural Network Model, 2015.</a></li>
		<li><a name="5" href="https://discourse.numenta.org/t/preliminary-details-about-new-theory-work-on-sensory-motor-inference/697">Discourse: Preliminary details about new theory work on sensory-motor inference</a></li>
	</ol>
			
	<p>WIP:</p>
	<p>https://discourse.numenta.org/t/temporal-memory-handling-no-previous-winner-cells/1250</p>
	<p>https://discourse.numenta.org/t/understanding-the-phrase-layer-x-projects-to-layer-y/1192/3</p>
	
	<p>Page update: 2017-06-06</p>
	
</div>
</body>
</html>